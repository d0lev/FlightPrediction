{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c777a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.compat.v1 as tf \n",
    "import tensorflow.keras as keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b769b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset):\n",
    "    dataset = dataset.apply(lambda x: (x - x.min(axis = 0)) / (x.max(axis = 0) - x.min(axis = 0)))\n",
    "    dataset = dataset.loc[:,dataset.any()]\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "364a6bf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DAY</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DEP_TIME</th>\n",
       "      <th>ARR_TIME</th>\n",
       "      <th>ORIGIN_ABE</th>\n",
       "      <th>ORIGIN_ABI</th>\n",
       "      <th>ORIGIN_ABQ</th>\n",
       "      <th>ORIGIN_ABR</th>\n",
       "      <th>ORIGIN_ABY</th>\n",
       "      <th>...</th>\n",
       "      <th>DEST_USA</th>\n",
       "      <th>DEST_VEL</th>\n",
       "      <th>DEST_VLD</th>\n",
       "      <th>DEST_VPS</th>\n",
       "      <th>DEST_WRG</th>\n",
       "      <th>DEST_WYS</th>\n",
       "      <th>DEST_XNA</th>\n",
       "      <th>DEST_YAK</th>\n",
       "      <th>DEST_YUM</th>\n",
       "      <th>ARR_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.166195</td>\n",
       "      <td>0.709462</td>\n",
       "      <td>0.760734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.266667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.131058</td>\n",
       "      <td>0.435181</td>\n",
       "      <td>0.474364</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.041397</td>\n",
       "      <td>0.222176</td>\n",
       "      <td>0.263026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.059370</td>\n",
       "      <td>0.507295</td>\n",
       "      <td>0.549812</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.021002</td>\n",
       "      <td>0.550646</td>\n",
       "      <td>0.585244</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.068457</td>\n",
       "      <td>0.228012</td>\n",
       "      <td>0.300542</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.272727</td>\n",
       "      <td>0.265347</td>\n",
       "      <td>0.762401</td>\n",
       "      <td>0.837849</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.080775</td>\n",
       "      <td>0.726553</td>\n",
       "      <td>0.807003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.251414</td>\n",
       "      <td>0.472697</td>\n",
       "      <td>0.683201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.061793</td>\n",
       "      <td>0.273864</td>\n",
       "      <td>0.337641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 708 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        DAY     MONTH  DISTANCE  DEP_TIME  ARR_TIME  ORIGIN_ABE  ORIGIN_ABI  \\\n",
       "0  0.066667  0.272727  0.166195  0.709462  0.760734         0.0         0.0   \n",
       "1  0.266667  1.000000  0.131058  0.435181  0.474364         0.0         0.0   \n",
       "2  0.133333  0.181818  0.041397  0.222176  0.263026         0.0         0.0   \n",
       "3  0.666667  0.363636  0.059370  0.507295  0.549812         0.0         0.0   \n",
       "4  0.166667  0.272727  0.021002  0.550646  0.585244         0.0         0.0   \n",
       "5  0.333333  0.545455  0.068457  0.228012  0.300542         0.0         0.0   \n",
       "6  0.000000  0.272727  0.265347  0.762401  0.837849         0.0         0.0   \n",
       "7  0.733333  0.090909  0.080775  0.726553  0.807003         0.0         0.0   \n",
       "8  0.100000  0.363636  0.251414  0.472697  0.683201         0.0         0.0   \n",
       "9  0.533333  0.818182  0.061793  0.273864  0.337641         0.0         0.0   \n",
       "\n",
       "   ORIGIN_ABQ  ORIGIN_ABR  ORIGIN_ABY  ...  DEST_USA  DEST_VEL  DEST_VLD  \\\n",
       "0         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "1         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "2         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "3         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "4         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "5         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "6         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "7         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "8         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "9         0.0         0.0         0.0  ...       0.0       0.0       0.0   \n",
       "\n",
       "   DEST_VPS  DEST_WRG  DEST_WYS  DEST_XNA  DEST_YAK  DEST_YUM  ARR_DELAY  \n",
       "0       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "1       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "2       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "3       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "4       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "5       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "6       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "7       0.0       0.0       0.0       0.0       0.0       0.0        1.0  \n",
       "8       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "9       0.0       0.0       0.0       0.0       0.0       0.0        0.0  \n",
       "\n",
       "[10 rows x 708 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"2018.csv\" , index_col = 0)\n",
    "dataset = normalize(dataset.iloc[:,:])\n",
    "# Splitting the dataset into train 70% and test 30%\n",
    "features = (dataset.shape[1] - 1)\n",
    "examples = dataset.shape[0]\n",
    "train_size = int (0.7 * len(dataset))\n",
    "(x_train , y_train) = (np.array(dataset.iloc[:train_size,:features]), np.array(dataset.iloc[:train_size,features:]))\n",
    "(x_test , y_test) = (np.array(dataset.iloc[train_size:,:features]), np.array(dataset.iloc[train_size:,features:]))\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cb784d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters \n",
    "learning_rate = 0.0001\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "batches = int (train_size / batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2216d91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  0  Accuracy: 1.0 loss: 0.7634338\n",
      "Iteration:  1  Accuracy: 1.0 loss: 0.7627952\n",
      "Iteration:  2  Accuracy: 1.0 loss: 0.76216155\n",
      "Iteration:  3  Accuracy: 1.0 loss: 0.76153296\n",
      "Iteration:  4  Accuracy: 1.0 loss: 0.76090956\n",
      "Iteration:  5  Accuracy: 1.0 loss: 0.76029146\n",
      "Iteration:  6  Accuracy: 1.0 loss: 0.75967866\n",
      "Iteration:  7  Accuracy: 1.0 loss: 0.7590711\n",
      "Iteration:  8  Accuracy: 1.0 loss: 0.7584691\n",
      "Iteration:  9  Accuracy: 1.0 loss: 0.7578724\n",
      "Iteration:  10  Accuracy: 1.0 loss: 0.75728124\n",
      "Iteration:  11  Accuracy: 1.0 loss: 0.7566957\n",
      "Iteration:  12  Accuracy: 1.0 loss: 0.7561157\n",
      "Iteration:  13  Accuracy: 1.0 loss: 0.7555411\n",
      "Iteration:  14  Accuracy: 1.0 loss: 0.7549722\n",
      "Iteration:  15  Accuracy: 1.0 loss: 0.7544091\n",
      "Iteration:  16  Accuracy: 1.0 loss: 0.7538515\n",
      "Iteration:  17  Accuracy: 1.0 loss: 0.75329965\n",
      "Iteration:  18  Accuracy: 1.0 loss: 0.7527533\n",
      "Iteration:  19  Accuracy: 1.0 loss: 0.7522128\n",
      "Iteration:  20  Accuracy: 1.0 loss: 0.7516779\n",
      "Iteration:  21  Accuracy: 1.0 loss: 0.7511487\n",
      "Iteration:  22  Accuracy: 1.0 loss: 0.75062513\n",
      "Iteration:  23  Accuracy: 1.0 loss: 0.7501073\n",
      "Iteration:  24  Accuracy: 1.0 loss: 0.74959487\n",
      "Iteration:  25  Accuracy: 1.0 loss: 0.74908847\n",
      "Iteration:  26  Accuracy: 1.0 loss: 0.7485874\n",
      "Iteration:  27  Accuracy: 1.0 loss: 0.74809206\n",
      "Iteration:  28  Accuracy: 1.0 loss: 0.7476022\n",
      "Iteration:  29  Accuracy: 1.0 loss: 0.747118\n",
      "Iteration:  30  Accuracy: 1.0 loss: 0.74663925\n",
      "Iteration:  31  Accuracy: 1.0 loss: 0.74616605\n",
      "Iteration:  32  Accuracy: 1.0 loss: 0.7456984\n",
      "Iteration:  33  Accuracy: 1.0 loss: 0.74523604\n",
      "Iteration:  34  Accuracy: 1.0 loss: 0.7447792\n",
      "Iteration:  35  Accuracy: 1.0 loss: 0.7443277\n",
      "Iteration:  36  Accuracy: 1.0 loss: 0.7438816\n",
      "Iteration:  37  Accuracy: 1.0 loss: 0.7434407\n",
      "Iteration:  38  Accuracy: 1.0 loss: 0.74300504\n",
      "Iteration:  39  Accuracy: 1.0 loss: 0.74257475\n",
      "Iteration:  40  Accuracy: 1.0 loss: 0.74214953\n",
      "Iteration:  41  Accuracy: 1.0 loss: 0.74172944\n",
      "Iteration:  42  Accuracy: 1.0 loss: 0.7413145\n",
      "Iteration:  43  Accuracy: 1.0 loss: 0.74090445\n",
      "Iteration:  44  Accuracy: 1.0 loss: 0.7404995\n",
      "Iteration:  45  Accuracy: 1.0 loss: 0.7400995\n",
      "Iteration:  46  Accuracy: 1.0 loss: 0.7397043\n",
      "Iteration:  47  Accuracy: 1.0 loss: 0.73931396\n",
      "Iteration:  48  Accuracy: 1.0 loss: 0.73892856\n",
      "Iteration:  49  Accuracy: 1.0 loss: 0.73854774\n",
      "Iteration:  50  Accuracy: 1.0 loss: 0.7381717\n",
      "Iteration:  51  Accuracy: 1.0 loss: 0.7378003\n",
      "Iteration:  52  Accuracy: 1.0 loss: 0.7374335\n",
      "Iteration:  53  Accuracy: 1.0 loss: 0.7370712\n",
      "Iteration:  54  Accuracy: 1.0 loss: 0.7367134\n",
      "Iteration:  55  Accuracy: 1.0 loss: 0.73636\n",
      "Iteration:  56  Accuracy: 1.0 loss: 0.736011\n",
      "Iteration:  57  Accuracy: 1.0 loss: 0.7356665\n",
      "Iteration:  58  Accuracy: 1.0 loss: 0.7353262\n",
      "Iteration:  59  Accuracy: 1.0 loss: 0.73499\n",
      "Iteration:  60  Accuracy: 1.0 loss: 0.7346581\n",
      "Iteration:  61  Accuracy: 1.0 loss: 0.7343303\n",
      "Iteration:  62  Accuracy: 1.0 loss: 0.7340065\n",
      "Iteration:  63  Accuracy: 1.0 loss: 0.7336868\n",
      "Iteration:  64  Accuracy: 1.0 loss: 0.733371\n",
      "Iteration:  65  Accuracy: 1.0 loss: 0.7330592\n",
      "Iteration:  66  Accuracy: 1.0 loss: 0.7327513\n",
      "Iteration:  67  Accuracy: 1.0 loss: 0.732447\n",
      "Iteration:  68  Accuracy: 1.0 loss: 0.7321467\n",
      "Iteration:  69  Accuracy: 1.0 loss: 0.73185\n",
      "Iteration:  70  Accuracy: 1.0 loss: 0.731557\n",
      "Iteration:  71  Accuracy: 1.0 loss: 0.73126763\n",
      "Iteration:  72  Accuracy: 1.0 loss: 0.73098177\n",
      "Iteration:  73  Accuracy: 1.0 loss: 0.73069954\n",
      "Iteration:  74  Accuracy: 1.0 loss: 0.7304207\n",
      "Iteration:  75  Accuracy: 1.0 loss: 0.7301453\n",
      "Iteration:  76  Accuracy: 1.0 loss: 0.7298732\n",
      "Iteration:  77  Accuracy: 1.0 loss: 0.7296045\n",
      "Iteration:  78  Accuracy: 1.0 loss: 0.729339\n",
      "Iteration:  79  Accuracy: 1.0 loss: 0.72907686\n",
      "Iteration:  80  Accuracy: 1.0 loss: 0.7288178\n",
      "Iteration:  81  Accuracy: 1.0 loss: 0.728562\n",
      "Iteration:  82  Accuracy: 1.0 loss: 0.72830933\n",
      "Iteration:  83  Accuracy: 1.0 loss: 0.72805953\n",
      "Iteration:  84  Accuracy: 1.0 loss: 0.7278129\n",
      "Iteration:  85  Accuracy: 1.0 loss: 0.7275691\n",
      "Iteration:  86  Accuracy: 1.0 loss: 0.72732836\n",
      "Iteration:  87  Accuracy: 1.0 loss: 0.7270905\n",
      "Iteration:  88  Accuracy: 1.0 loss: 0.72685546\n",
      "Iteration:  89  Accuracy: 1.0 loss: 0.72662306\n",
      "Iteration:  90  Accuracy: 1.0 loss: 0.72639376\n",
      "Iteration:  91  Accuracy: 1.0 loss: 0.72616684\n",
      "Iteration:  92  Accuracy: 1.0 loss: 0.72594285\n",
      "Iteration:  93  Accuracy: 1.0 loss: 0.7257214\n",
      "Iteration:  94  Accuracy: 1.0 loss: 0.72550255\n",
      "Iteration:  95  Accuracy: 1.0 loss: 0.72528625\n",
      "Iteration:  96  Accuracy: 1.0 loss: 0.7250726\n",
      "Iteration:  97  Accuracy: 1.0 loss: 0.72486144\n",
      "Iteration:  98  Accuracy: 1.0 loss: 0.72465265\n",
      "Iteration:  99  Accuracy: 1.0 loss: 0.72444624\n"
     ]
    }
   ],
   "source": [
    "x = tf.placeholder(tf.float32 , [None , features])\n",
    "y = tf.placeholder(tf.float32 , [None , 1])\n",
    "\n",
    "W = tf.Variable(tf.zeros([features, 1]))\n",
    "b = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "pred = tf.nn.sigmoid(tf.matmul(x,W) + b)  \n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = y, logits = pred))\n",
    "\n",
    "update = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# Define accuracy - Percentage of predictions did we get right\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1),tf.argmax(y, 1)) \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "for epoch in range(100):     \n",
    "    for row in range(batches):        \n",
    "        batch_x = x_train [row * batch_size : (row + 1) * batch_size]\n",
    "        batch_y = y_train [row * batch_size : (row + 1) * batch_size]\n",
    "        session.run(update ,feed_dict = {x : batch_x , y : batch_y})\n",
    "        _, loss_val = session.run([update, loss],feed_dict={x: batch_x, y: batch_y})\n",
    "        \n",
    "    print(\"Iteration: \",epoch, \" Accuracy:\", session.run(accuracy, feed_dict={x: x_test, y: y_test}),\"loss:\",loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30feb402",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2730646314731332"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def logistic_fun(z):\n",
    "    return 1/(1.0 + np.exp(-z))\n",
    "\n",
    "x = dataset.iloc[0:1,:-1]\n",
    "logistic_fun(np.matmul(np.array(x),session.run(W)) + session.run(b))[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
